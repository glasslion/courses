{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division,print_function\n",
    "\n",
    "import os, json\n",
    "import shutil\n",
    "from glob import glob\n",
    "import random\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla P100-PCIE-16GB (CNMeM is disabled, cuDNN not available)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import utils; reload(utils)\n",
    "from utils import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Nadam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation set and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_ROOT = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_HOME_DIR = os.path.join(NB_ROOT, \"data/invasive-species-monitoring\")\n",
    "results_path = os.path.join('/mnt/data/invasive-species-monitoring', 'results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ml/working/fastai-courses/deeplearning1/nbs/data/invasive-species-monitoring\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "%mkdir -p valid\n",
    "%mkdir -p results\n",
    "%mkdir -p sample/train\n",
    "%mkdir -p sample/test/unknown\n",
    "%mkdir -p sample/valid\n",
    "%mkdir -p sample/results\n",
    "%mkdir -p test/unknown\n",
    "%mkdir -p /mnt/data/invasive-species-monitoring/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_label_dirs(base_dir):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Create label directories thant can be recognized by Keras ImageDataGenerator.flow_from_directory    \n",
    "    labels = ['invasive', 'not_invasive']\n",
    "    for label in labels:\n",
    "        try:\n",
    "            os.makedirs(os.path.join(base_dir, label))\n",
    "        except OSError as e:\n",
    "            if e.errno != os.errno.EEXIST:\n",
    "                raise\n",
    "\n",
    "create_label_dirs('train')\n",
    "create_label_dirs('valid')\n",
    "create_label_dirs('sample/train')\n",
    "create_label_dirs('sample/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels_csv = pd.read_csv(\"train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_images_by_dir(base_dir=\"train\"):\n",
    "    \"\"\"\n",
    "    Move images into their label directory so that they can be recognized by\n",
    "    ImageDataGenerator.flow_from_directory\n",
    "    \"\"\"\n",
    "    for _, row in train_labels_csv.iterrows():\n",
    "        image_name = \"{}.jpg\".format(row['name'])\n",
    "        src_path = os.path.join(base_dir, image_name)\n",
    "        if row['invasive'] == 1:\n",
    "            dst_path = os.path.join(base_dir, 'invasive', image_name)\n",
    "        else:\n",
    "            dst_path = \"train/not_invasive/{}\".format(image_name)\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.move(src_path, dst_path)\n",
    "# label_images_by_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_valid_set(train_root='train', valid_root=\"valid\", valid_rate=0.1):\n",
    "    labels = ['invasive', 'not_invasive']\n",
    "    for label in labels:\n",
    "        train_label_dir = os.path.join(train_root, label)\n",
    "        valid_label_dir = os.path.join(valid_root, label)\n",
    "        files = os.listdir(train_label_dir)\n",
    "        for file in random.sample(files, k=int(len(files) * valid_rate)):\n",
    "            shutil.move(os.path.join(train_label_dir, file), valid_label_dir)\n",
    "# create_valid_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_sample_set(rate=0.01):\n",
    "    labels = ['invasive', 'not_invasive', 'unknown']\n",
    "    for dataset in ['train', 'valid', 'test']:\n",
    "        if dataset == \"valid\":\n",
    "            # use a higher smple rate for the validation dataset\n",
    "            # because they have fewer items\n",
    "            sample_rate = rate*5\n",
    "        else:\n",
    "            sample_rate = rate\n",
    "        for label in labels:\n",
    "            src_dir = os.path.join(dataset, label)\n",
    "            dst_dir = os.path.join('sample', dataset, label)\n",
    "            try:\n",
    "                files = os.listdir(src_dir)\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            for file in random.sample(files, k=int(len(files) * sample_rate)):\n",
    "                shutil.copy(os.path.join(src_dir, file), dst_dir)\n",
    "\n",
    "# create_sample_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_size = (600, 450)\n",
    "# target_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3, 600, 450)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 600, 450)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 600, 450)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 300, 225)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 300, 225)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 300, 225)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 128, 150, 112)     0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 256, 150, 112)     295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 256, 150, 112)     590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 256, 150, 112)     590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 256, 75, 56)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 512, 75, 56)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 512, 75, 56)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 512, 75, 56)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 512, 37, 28)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 512, 37, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 512, 37, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 512, 37, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 512, 18, 14)       0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 2)                 33030914  \n",
      "=================================================================\n",
      "Total params: 47,745,602\n",
      "Trainable params: 33,030,914\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    img_rows, img_cols = target_size\n",
    "    img_channel = 3\n",
    "    base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_channel,img_rows, img_cols))\n",
    "    base_model\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    add_model = Sequential()\n",
    "    add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "    add_model.add(Dense(256, activation='relu'))\n",
    "    add_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_path = DATA_HOME_DIR\n",
    "# _path = DATA_HOME_DIR + '/sample' # Only for sample tests!\n",
    "test_path = os.path.join(DATA_HOME_DIR, 'test')\n",
    "train_path = os.path.join(_path, 'train')\n",
    "valid_path = os.path.join(_path, 'valid')\n",
    "test_path = os.path.join(_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(path, gen=image.ImageDataGenerator(), shuffle=True, batch_size=8, target_size=(224,224), class_mode='categorical'):\n",
    "        \"\"\"\n",
    "            Takes the path to a directory, and generates batches of augmented/normalized data. Yields batches indefinitely, in an infinite loop.\n",
    "\n",
    "            See Keras documentation: https://keras.io/preprocessing/image/\n",
    "        \"\"\"\n",
    "        # 224x224 is the image size used by ImageNet\n",
    "        return gen.flow_from_directory(path, target_size=target_size,\n",
    "                class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2067 images belonging to 2 classes.\n",
      "Found 228 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "! cd $NB_ROOT\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "trans_gen = image.ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1, height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    " \n",
    "train_batches = get_batches(train_path, gen=trans_gen, batch_size=BATCH_SIZE, target_size=target_size)\n",
    "valid_batches = get_batches(valid_path, batch_size=BATCH_SIZE*2, target_size=target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(model, no_of_epochs = 10):\n",
    "    latest_weights_filename = None\n",
    "    for epoch in range(no_of_epochs):\n",
    "        print(\"Running epoch: %d\" % epoch)\n",
    "        model.fit_generator(\n",
    "            train_batches,\n",
    "            epochs=1,\n",
    "            steps_per_epoch=train_batches.samples//BATCH_SIZE,\n",
    "            validation_data=valid_batches, validation_steps=valid_batches.samples//BATCH_SIZE,\n",
    "        )\n",
    "        latest_weights_filename = 'ft%d.h5' % epoch\n",
    "        model.save_weights(os.path.join(results_path, latest_weights_filename))\n",
    "        print(\"Completed %s fit operations\" % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 0\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 164s 3s/step - loss: 2.6621 - acc: 0.7964 - val_loss: 1.7889 - val_acc: 0.8684\n",
      "Completed 0 fit operations\n",
      "Running epoch: 1\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 2.2002 - acc: 0.8448 - val_loss: 1.5100 - val_acc: 0.8816\n",
      "Completed 1 fit operations\n",
      "Running epoch: 2\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 2.4930 - acc: 0.8267 - val_loss: 1.7410 - val_acc: 0.8728\n",
      "Completed 2 fit operations\n",
      "Running epoch: 3\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 1.9516 - acc: 0.8630 - val_loss: 1.2841 - val_acc: 0.9079\n",
      "Completed 3 fit operations\n",
      "Running epoch: 4\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 1.7824 - acc: 0.8786 - val_loss: 1.6662 - val_acc: 0.8904\n",
      "Completed 4 fit operations\n",
      "Running epoch: 5\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 2.0856 - acc: 0.8599 - val_loss: 0.9590 - val_acc: 0.9211\n",
      "Completed 5 fit operations\n",
      "Running epoch: 6\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 1.5775 - acc: 0.8924 - val_loss: 1.4040 - val_acc: 0.9079\n",
      "Completed 6 fit operations\n",
      "Running epoch: 7\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 1.3943 - acc: 0.8983 - val_loss: 1.2502 - val_acc: 0.9167\n",
      "Completed 7 fit operations\n",
      "Running epoch: 8\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 1.1984 - acc: 0.9154 - val_loss: 1.1072 - val_acc: 0.9211\n",
      "Completed 8 fit operations\n",
      "Running epoch: 9\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 1.2100 - acc: 0.9145 - val_loss: 0.9415 - val_acc: 0.9386\n",
      "Completed 9 fit operations\n",
      "Running epoch: 10\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 1.2342 - acc: 0.9120 - val_loss: 1.1677 - val_acc: 0.9167\n",
      "Completed 10 fit operations\n",
      "Running epoch: 11\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 1.4008 - acc: 0.9056 - val_loss: 1.1831 - val_acc: 0.9211\n",
      "Completed 11 fit operations\n",
      "Running epoch: 12\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 1.1515 - acc: 0.9181 - val_loss: 0.7273 - val_acc: 0.9474\n",
      "Completed 12 fit operations\n",
      "Running epoch: 13\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 1.0672 - acc: 0.9243 - val_loss: 0.6578 - val_acc: 0.9474\n",
      "Completed 13 fit operations\n",
      "Running epoch: 14\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 1.4609 - acc: 0.8954 - val_loss: 1.1157 - val_acc: 0.9211\n",
      "Completed 14 fit operations\n",
      "Running epoch: 15\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 1.0782 - acc: 0.9256 - val_loss: 1.0144 - val_acc: 0.9298\n",
      "Completed 15 fit operations\n",
      "Running epoch: 16\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 1.2900 - acc: 0.9067 - val_loss: 0.8650 - val_acc: 0.9386\n",
      "Completed 16 fit operations\n",
      "Running epoch: 17\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 1.0570 - acc: 0.9211 - val_loss: 1.0967 - val_acc: 0.9211\n",
      "Completed 17 fit operations\n",
      "Running epoch: 18\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 1.0719 - acc: 0.9187 - val_loss: 1.0057 - val_acc: 0.9254\n",
      "Completed 18 fit operations\n",
      "Running epoch: 19\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 0.9630 - acc: 0.9272 - val_loss: 0.7844 - val_acc: 0.9386\n",
      "Completed 19 fit operations\n"
     ]
    }
   ],
   "source": [
    "fit_model(model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 0\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.8121 - acc: 0.9361 - val_loss: 0.9702 - val_acc: 0.9211\n",
      "Completed 0 fit operations\n",
      "Running epoch: 1\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.8260 - acc: 0.9344 - val_loss: 0.8386 - val_acc: 0.9386\n",
      "Completed 1 fit operations\n",
      "Running epoch: 2\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 0.7518 - acc: 0.9398 - val_loss: 0.7715 - val_acc: 0.9298\n",
      "Completed 2 fit operations\n",
      "Running epoch: 3\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 0.8236 - acc: 0.9330 - val_loss: 0.7743 - val_acc: 0.9298\n",
      "Completed 3 fit operations\n",
      "Running epoch: 4\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 0.6989 - acc: 0.9403 - val_loss: 0.7122 - val_acc: 0.9342\n",
      "Completed 4 fit operations\n",
      "Running epoch: 5\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 0.7375 - acc: 0.9356 - val_loss: 0.5406 - val_acc: 0.9474\n",
      "Completed 5 fit operations\n",
      "Running epoch: 6\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.4675 - acc: 0.9459 - val_loss: 0.4206 - val_acc: 0.9386\n",
      "Completed 6 fit operations\n",
      "Running epoch: 7\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.2772 - acc: 0.9386 - val_loss: 0.2291 - val_acc: 0.9430\n",
      "Completed 7 fit operations\n",
      "Running epoch: 8\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 0.1611 - acc: 0.9470 - val_loss: 0.1543 - val_acc: 0.9386\n",
      "Completed 8 fit operations\n",
      "Running epoch: 9\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.1478 - acc: 0.9476 - val_loss: 0.1462 - val_acc: 0.9386\n",
      "Completed 9 fit operations\n",
      "Running epoch: 10\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 0.1063 - acc: 0.9604 - val_loss: 0.1545 - val_acc: 0.9386\n",
      "Completed 10 fit operations\n",
      "Running epoch: 11\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.1289 - acc: 0.9515 - val_loss: 0.1434 - val_acc: 0.9518\n",
      "Completed 11 fit operations\n",
      "Running epoch: 12\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.1183 - acc: 0.9563 - val_loss: 0.1537 - val_acc: 0.9518\n",
      "Completed 12 fit operations\n",
      "Running epoch: 13\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.1257 - acc: 0.9524 - val_loss: 0.1420 - val_acc: 0.9430\n",
      "Completed 13 fit operations\n",
      "Running epoch: 14\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.1115 - acc: 0.9612 - val_loss: 0.1553 - val_acc: 0.9518\n",
      "Completed 14 fit operations\n",
      "Running epoch: 15\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 0.1336 - acc: 0.9510 - val_loss: 0.1477 - val_acc: 0.9474\n",
      "Completed 15 fit operations\n",
      "Running epoch: 16\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.1118 - acc: 0.9624 - val_loss: 0.1376 - val_acc: 0.9474\n",
      "Completed 16 fit operations\n",
      "Running epoch: 17\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.1032 - acc: 0.9578 - val_loss: 0.1528 - val_acc: 0.9518\n",
      "Completed 17 fit operations\n",
      "Running epoch: 18\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 0.1001 - acc: 0.9645 - val_loss: 0.1421 - val_acc: 0.9561\n",
      "Completed 18 fit operations\n",
      "Running epoch: 19\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 0.0981 - acc: 0.9614 - val_loss: 0.1455 - val_acc: 0.9518\n",
      "Completed 19 fit operations\n"
     ]
    }
   ],
   "source": [
    "fit_model(model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 0\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 0.1027 - acc: 0.9558 - val_loss: 0.1530 - val_acc: 0.9518\n",
      "Completed 0 fit operations\n",
      "Running epoch: 1\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.1017 - acc: 0.9670 - val_loss: 0.1377 - val_acc: 0.9474\n",
      "Completed 1 fit operations\n",
      "Running epoch: 2\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 0.0853 - acc: 0.9628 - val_loss: 0.1431 - val_acc: 0.9518\n",
      "Completed 2 fit operations\n",
      "Running epoch: 3\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.0815 - acc: 0.9706 - val_loss: 0.1572 - val_acc: 0.9518\n",
      "Completed 3 fit operations\n",
      "Running epoch: 4\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 0.1027 - acc: 0.9629 - val_loss: 0.1492 - val_acc: 0.9518\n",
      "Completed 4 fit operations\n",
      "Running epoch: 5\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.0861 - acc: 0.9656 - val_loss: 0.1277 - val_acc: 0.9561\n",
      "Completed 5 fit operations\n",
      "Running epoch: 6\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.0900 - acc: 0.9664 - val_loss: 0.1444 - val_acc: 0.9561\n",
      "Completed 6 fit operations\n",
      "Running epoch: 7\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 0.0881 - acc: 0.9697 - val_loss: 0.1364 - val_acc: 0.9561\n",
      "Completed 7 fit operations\n",
      "Running epoch: 8\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.0918 - acc: 0.9666 - val_loss: 0.1358 - val_acc: 0.9518\n",
      "Completed 8 fit operations\n",
      "Running epoch: 9\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.0865 - acc: 0.9692 - val_loss: 0.1331 - val_acc: 0.9518\n",
      "Completed 9 fit operations\n",
      "Running epoch: 10\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 0.0830 - acc: 0.9684 - val_loss: 0.1250 - val_acc: 0.9649\n",
      "Completed 10 fit operations\n",
      "Running epoch: 11\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.0864 - acc: 0.9678 - val_loss: 0.1307 - val_acc: 0.9561\n",
      "Completed 11 fit operations\n",
      "Running epoch: 12\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.0845 - acc: 0.9663 - val_loss: 0.1313 - val_acc: 0.9518\n",
      "Completed 12 fit operations\n",
      "Running epoch: 13\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.0836 - acc: 0.9695 - val_loss: 0.1323 - val_acc: 0.9605\n",
      "Completed 13 fit operations\n",
      "Running epoch: 14\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.0679 - acc: 0.9714 - val_loss: 0.1439 - val_acc: 0.9474\n",
      "Completed 14 fit operations\n",
      "Running epoch: 15\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.0832 - acc: 0.9743 - val_loss: 0.1552 - val_acc: 0.9693\n",
      "Completed 15 fit operations\n",
      "Running epoch: 16\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 156s 2s/step - loss: 0.0808 - acc: 0.9687 - val_loss: 0.1420 - val_acc: 0.9561\n",
      "Completed 16 fit operations\n",
      "Running epoch: 17\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 157s 2s/step - loss: 0.0594 - acc: 0.9753 - val_loss: 0.1455 - val_acc: 0.9518\n",
      "Completed 17 fit operations\n",
      "Running epoch: 18\n",
      "Epoch 1/1\n",
      "56/64 [=========================>....] - ETA: 17s - loss: 0.0745 - acc: 0.9654"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-4a1188dcfaba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-cdffff911e85>\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(model, no_of_epochs)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         )\n\u001b[1;32m     11\u001b[0m         \u001b[0mlatest_weights_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ft%d.h5'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ml/libs/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ml/libs/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2081\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2083\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2085\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ml/libs/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ml/libs/anaconda3/envs/fastai/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ml/libs/anaconda3/envs/fastai/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ml/libs/anaconda3/envs/fastai/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ml/libs/anaconda3/envs/fastai/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit_model(model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(results_path, 'ft15.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1531 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = get_batches(\n",
    "    test_path, batch_size=BATCH_SIZE * 2, target_size=target_size, shuffle=False, class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, test_batches):\n",
    "    return model.predict_generator(test_batches, test_batches.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = predict(model, test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sbm = pd.DataFrame(preds, columns=[\"invasive\",\"not invasive\"])\n",
    "sbm['name'] = [int(f.replace('unknown/', '').replace('.jpg', '')) for f in test_batches.filenames]\n",
    "sbm = sbm.set_index(['name'])\n",
    "sbm = sbm.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sbm.to_csv('submission.csv', columns=['invasive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97237\r\n"
     ]
    }
   ],
   "source": [
    "!kg submit -c invasive-species-monitoring submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
