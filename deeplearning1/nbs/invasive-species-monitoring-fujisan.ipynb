{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division,print_function\n",
    "\n",
    "import os, json\n",
    "import shutil\n",
    "from glob import glob\n",
    "import random\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla P100-PCIE-16GB (CNMeM is disabled, cuDNN not available)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import utils; reload(utils)\n",
    "from utils import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Nadam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation set and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_ROOT = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_HOME_DIR = os.path.join(NB_ROOT, \"data/invasive-species-monitoring\")\n",
    "results_path = os.path.join('/mnt/data/invasive-species-monitoring', 'results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ml/working/fastai-courses/deeplearning1/nbs/data/invasive-species-monitoring\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "%mkdir -p valid\n",
    "%mkdir -p results\n",
    "%mkdir -p sample/train\n",
    "%mkdir -p sample/test/unknown\n",
    "%mkdir -p sample/valid\n",
    "%mkdir -p sample/results\n",
    "%mkdir -p test/unknown\n",
    "%mkdir -p /mnt/data/invasive-species-monitoring/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_label_dirs(base_dir):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Create label directories thant can be recognized by Keras ImageDataGenerator.flow_from_directory    \n",
    "    labels = ['invasive', 'not_invasive']\n",
    "    for label in labels:\n",
    "        try:\n",
    "            os.makedirs(os.path.join(base_dir, label))\n",
    "        except OSError as e:\n",
    "            if e.errno != os.errno.EEXIST:\n",
    "                raise\n",
    "\n",
    "create_label_dirs('train')\n",
    "create_label_dirs('valid')\n",
    "create_label_dirs('sample/train')\n",
    "create_label_dirs('sample/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels_csv = pd.read_csv(\"train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_images_by_dir(base_dir=\"train\"):\n",
    "    \"\"\"\n",
    "    Move images into their label directory so that they can be recognized by\n",
    "    ImageDataGenerator.flow_from_directory\n",
    "    \"\"\"\n",
    "    for _, row in train_labels_csv.iterrows():\n",
    "        image_name = \"{}.jpg\".format(row['name'])\n",
    "        src_path = os.path.join(base_dir, image_name)\n",
    "        if row['invasive'] == 1:\n",
    "            dst_path = os.path.join(base_dir, 'invasive', image_name)\n",
    "        else:\n",
    "            dst_path = \"train/not_invasive/{}\".format(image_name)\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.move(src_path, dst_path)\n",
    "# label_images_by_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_valid_set(train_root='train', valid_root=\"valid\", valid_rate=0.1):\n",
    "    labels = ['invasive', 'not_invasive']\n",
    "    for label in labels:\n",
    "        train_label_dir = os.path.join(train_root, label)\n",
    "        valid_label_dir = os.path.join(valid_root, label)\n",
    "        files = os.listdir(train_label_dir)\n",
    "        for file in random.sample(files, k=int(len(files) * valid_rate)):\n",
    "            shutil.move(os.path.join(train_label_dir, file), valid_label_dir)\n",
    "# create_valid_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_sample_set(rate=0.01):\n",
    "    labels = ['invasive', 'not_invasive', 'unknown']\n",
    "    for dataset in ['train', 'valid', 'test']:\n",
    "        if dataset == \"valid\":\n",
    "            # use a higher smple rate for the validation dataset\n",
    "            # because they have fewer items\n",
    "            sample_rate = rate*5\n",
    "        else:\n",
    "            sample_rate = rate\n",
    "        for label in labels:\n",
    "            src_dir = os.path.join(dataset, label)\n",
    "            dst_dir = os.path.join('sample', dataset, label)\n",
    "            try:\n",
    "                files = os.listdir(src_dir)\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            for file in random.sample(files, k=int(len(files) * sample_rate)):\n",
    "                shutil.copy(os.path.join(src_dir, file), dst_dir)\n",
    "\n",
    "# create_sample_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 3, 224, 224)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 224, 224)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 224, 224)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 112, 112)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 112, 112)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 112, 112)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 128, 56, 56)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 256, 56, 56)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 256, 28, 28)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 512, 28, 28)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 512, 14, 14)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 512, 7, 7)         0         \n",
      "_________________________________________________________________\n",
      "sequential_8 (Sequential)    (None, 2)                 6423298   \n",
      "=================================================================\n",
      "Total params: 21,137,986\n",
      "Trainable params: 6,423,298\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    img_rows, img_cols, img_channel = 224, 224, 3\n",
    "    base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_channel,img_rows, img_cols))\n",
    "    base_model\n",
    "    \n",
    "    for layer in base_model.layers[:-5]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    add_model = Sequential()\n",
    "    add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "    add_model.add(Dense(256, activation='relu'))\n",
    "    add_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_path = DATA_HOME_DIR\n",
    "# _path = DATA_HOME_DIR + '/sample' # Only for sample tests!\n",
    "test_path = os.path.join(DATA_HOME_DIR, 'test')\n",
    "train_path = os.path.join(_path, 'train')\n",
    "valid_path = os.path.join(_path, 'valid')\n",
    "test_path = os.path.join(_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(path, gen=image.ImageDataGenerator(), shuffle=True, batch_size=8, target_size=(224,224), class_mode='categorical'):\n",
    "        \"\"\"\n",
    "            Takes the path to a directory, and generates batches of augmented/normalized data. Yields batches indefinitely, in an infinite loop.\n",
    "\n",
    "            See Keras documentation: https://keras.io/preprocessing/image/\n",
    "        \"\"\"\n",
    "        # 224x224 is the image size used by ImageNet\n",
    "        return gen.flow_from_directory(path, target_size=target_size,\n",
    "                class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2067 images belonging to 2 classes.\n",
      "Found 228 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "! cd $NB_ROOT\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "trans_gen = image.ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1, height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "# target_size = (600, 450)\n",
    "target_size = (224, 224) \n",
    "train_batches = get_batches(train_path, batch_size=BATCH_SIZE, target_size=target_size)\n",
    "valid_batches = get_batches(valid_path, batch_size=BATCH_SIZE*2, target_size=target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(model, no_of_epochs = 10):\n",
    "    latest_weights_filename = None\n",
    "    for epoch in range(no_of_epochs):\n",
    "        print(\"Running epoch: %d\" % epoch)\n",
    "        model.fit_generator(\n",
    "            train_batches,\n",
    "            epochs=1,\n",
    "            steps_per_epoch=train_batches.samples//BATCH_SIZE,\n",
    "            validation_data=valid_batches, validation_steps=valid_batches.samples//BATCH_SIZE,\n",
    "        )\n",
    "        latest_weights_filename = 'ft%d.h5' % epoch\n",
    "        model.save_weights(os.path.join(results_path, latest_weights_filename))\n",
    "        print(\"Completed %s fit operations\" % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 0\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 75s 1s/step - loss: 1.2797 - acc: 0.8625 - val_loss: 0.7807 - val_acc: 0.9123\n",
      "Completed 0 fit operations\n",
      "Running epoch: 1\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 75s 1s/step - loss: 0.4058 - acc: 0.9418 - val_loss: 0.5033 - val_acc: 0.9298\n",
      "Completed 1 fit operations\n",
      "Running epoch: 2\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 75s 1s/step - loss: 0.1823 - acc: 0.9727 - val_loss: 0.4135 - val_acc: 0.9211\n",
      "Completed 2 fit operations\n",
      "Running epoch: 3\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 75s 1s/step - loss: 0.1020 - acc: 0.9818 - val_loss: 0.3459 - val_acc: 0.9386\n",
      "Completed 3 fit operations\n",
      "Running epoch: 4\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 75s 1s/step - loss: 0.0518 - acc: 0.9958 - val_loss: 0.3883 - val_acc: 0.9298\n",
      "Completed 4 fit operations\n",
      "Running epoch: 5\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 75s 1s/step - loss: 0.0420 - acc: 0.9972 - val_loss: 0.3578 - val_acc: 0.9342\n",
      "Completed 5 fit operations\n",
      "Running epoch: 6\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 75s 1s/step - loss: 0.0388 - acc: 0.9977 - val_loss: 0.4027 - val_acc: 0.9342\n",
      "Completed 6 fit operations\n",
      "Running epoch: 7\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 75s 1s/step - loss: 0.0431 - acc: 0.9974 - val_loss: 0.3936 - val_acc: 0.9342\n",
      "Completed 7 fit operations\n",
      "Running epoch: 8\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 75s 1s/step - loss: 0.0380 - acc: 0.9977 - val_loss: 0.3921 - val_acc: 0.9342\n",
      "Completed 8 fit operations\n",
      "Running epoch: 9\n",
      "Epoch 1/1\n",
      "65/64 [==============================] - 75s 1s/step - loss: 0.0380 - acc: 0.9977 - val_loss: 0.4011 - val_acc: 0.9342\n",
      "Completed 9 fit operations\n"
     ]
    }
   ],
   "source": [
    "fit_model(model, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1531 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = get_batches(\n",
    "    test_path, batch_size=BATCH_SIZE * 2, target_size=target_size, shuffle=False, class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, test_batches):\n",
    "    return model.predict_generator(test_batches, test_batches.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(model, test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sbm = pd.DataFrame(preds, columns=[\"invasive\",\"not invasive\"])\n",
    "sbm['name'] = [int(f.replace('unknown/', '').replace('.jpg', '')) for f in test_batches.filenames]\n",
    "sbm = sbm.set_index(['name'])\n",
    "sbm = sbm.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invasive</th>\n",
       "      <th>not invasive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.998370e-01</td>\n",
       "      <td>1.628952e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.426485e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.480298e-04</td>\n",
       "      <td>9.997520e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.266575e-06</td>\n",
       "      <td>9.999937e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.826730e-01</td>\n",
       "      <td>1.732701e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.214716e-03</td>\n",
       "      <td>9.937853e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.842632e-05</td>\n",
       "      <td>9.999516e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.011632e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.057223e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.346138e-18</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.789711e-06</td>\n",
       "      <td>9.999912e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.793839e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.329107e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.134388e-04</td>\n",
       "      <td>9.992865e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.602905e-07</td>\n",
       "      <td>9.999994e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.574938e-13</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.798802e-01</td>\n",
       "      <td>2.011980e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.808240e-04</td>\n",
       "      <td>9.998192e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.652129e-05</td>\n",
       "      <td>9.999834e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.117248e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.059199e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>1.852088e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7.504755e-04</td>\n",
       "      <td>9.992495e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.044201e-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.846034e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.340442e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8.247809e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.033279e-03</td>\n",
       "      <td>9.989667e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5.378737e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>2.608298e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>5.929752e-07</td>\n",
       "      <td>9.999994e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>2.031771e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.653860e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>5.360792e-13</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>5.084709e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.301417e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.314120e-33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.453164e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>2.272934e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>5.225969e-05</td>\n",
       "      <td>9.999478e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>8.852170e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.443008e-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.550308e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.376755e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>3.780938e-04</td>\n",
       "      <td>9.996219e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>3.628205e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>4.650656e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>9.637608e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.640332e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>9.993413e-01</td>\n",
       "      <td>6.586763e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>9.999995e-01</td>\n",
       "      <td>4.393661e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>4.509005e-06</td>\n",
       "      <td>9.999955e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>1.237358e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.977766e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>3.648435e-06</td>\n",
       "      <td>9.999963e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.290118e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.488410e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1531 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          invasive  not invasive\n",
       "name                            \n",
       "1     9.998370e-01  1.628952e-04\n",
       "2     8.426485e-11  1.000000e+00\n",
       "3     2.480298e-04  9.997520e-01\n",
       "4     6.266575e-06  9.999937e-01\n",
       "5     9.826730e-01  1.732701e-02\n",
       "6     6.214716e-03  9.937853e-01\n",
       "7     4.842632e-05  9.999516e-01\n",
       "8     1.000000e+00  5.011632e-20\n",
       "9     1.000000e+00  0.000000e+00\n",
       "10    5.057223e-12  1.000000e+00\n",
       "11    1.346138e-18  1.000000e+00\n",
       "12    8.789711e-06  9.999912e-01\n",
       "13    1.793839e-08  1.000000e+00\n",
       "14    1.000000e+00  5.329107e-17\n",
       "15    7.134388e-04  9.992865e-01\n",
       "16    5.602905e-07  9.999994e-01\n",
       "17    1.574938e-13  1.000000e+00\n",
       "18    9.798802e-01  2.011980e-02\n",
       "19    1.808240e-04  9.998192e-01\n",
       "20    1.652129e-05  9.999834e-01\n",
       "21    1.000000e+00  9.117248e-25\n",
       "22    1.059199e-09  1.000000e+00\n",
       "23    9.999998e-01  1.852088e-07\n",
       "24    7.504755e-04  9.992495e-01\n",
       "25    1.000000e+00  1.044201e-30\n",
       "26    1.000000e+00  5.846034e-23\n",
       "27    1.000000e+00  3.340442e-13\n",
       "28    8.247809e-12  1.000000e+00\n",
       "29    1.033279e-03  9.989667e-01\n",
       "30    5.378737e-08  1.000000e+00\n",
       "...            ...           ...\n",
       "1502  2.608298e-08  1.000000e+00\n",
       "1503  5.929752e-07  9.999994e-01\n",
       "1504  2.031771e-07  9.999998e-01\n",
       "1505  1.000000e+00  0.000000e+00\n",
       "1506  1.000000e+00  1.653860e-25\n",
       "1507  5.360792e-13  1.000000e+00\n",
       "1508  5.084709e-08  1.000000e+00\n",
       "1509  1.000000e+00  1.301417e-11\n",
       "1510  1.000000e+00  1.314120e-33\n",
       "1511  1.000000e+00  8.453164e-12\n",
       "1512  2.272934e-09  1.000000e+00\n",
       "1513  5.225969e-05  9.999478e-01\n",
       "1514  1.000000e+00  0.000000e+00\n",
       "1515  8.852170e-12  1.000000e+00\n",
       "1516  1.000000e+00  8.443008e-30\n",
       "1517  1.000000e+00  4.550308e-22\n",
       "1518  1.000000e+00  1.376755e-11\n",
       "1519  3.780938e-04  9.996219e-01\n",
       "1520  3.628205e-15  1.000000e+00\n",
       "1521  4.650656e-08  1.000000e+00\n",
       "1522  9.637608e-08  9.999999e-01\n",
       "1523  1.000000e+00  8.640332e-15\n",
       "1524  9.993413e-01  6.586763e-04\n",
       "1525  9.999995e-01  4.393661e-07\n",
       "1526  4.509005e-06  9.999955e-01\n",
       "1527  1.237358e-10  1.000000e+00\n",
       "1528  1.000000e+00  3.977766e-25\n",
       "1529  3.648435e-06  9.999963e-01\n",
       "1530  1.000000e+00  9.290118e-09\n",
       "1531  1.000000e+00  1.488410e-17\n",
       "\n",
       "[1531 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sbm.to_csv('submission.csv', columns=['invasive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96217\r\n"
     ]
    }
   ],
   "source": [
    "!kg submit -c invasive-species-monitoring submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
