{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division,print_function\n",
    "\n",
    "import os, json\n",
    "import shutil\n",
    "from glob import glob\n",
    "import random\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import utils; reload(utils)\n",
    "from utils import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation set and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_ROOT = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_HOME_DIR = os.path.join(NB_ROOT, \"data/invasive-species-monitoring\")\n",
    "results_path = os.path.join(DATA_HOME_DIR, 'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/leo/src/fastai-courses/deeplearning1/nbs/data/invasive-species-monitoring\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "%mkdir -p valid\n",
    "%mkdir -p results\n",
    "%mkdir -p sample/train\n",
    "%mkdir -p sample/test/unknown\n",
    "%mkdir -p sample/valid\n",
    "%mkdir -p sample/results\n",
    "%mkdir -p test/unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_label_dirs(base_dir):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Create label directories thant can be recognized by Keras ImageDataGenerator.flow_from_directory    \n",
    "    labels = ['invasive', 'not_invasive']\n",
    "    for label in labels:\n",
    "        try:\n",
    "            os.makedirs(os.path.join(base_dir, label))\n",
    "        except OSError as e:\n",
    "            if e.errno != os.errno.EEXIST:\n",
    "                raise\n",
    "\n",
    "create_label_dirs('train')\n",
    "create_label_dirs('valid')\n",
    "create_label_dirs('sample/train')\n",
    "create_label_dirs('sample/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels_csv = pd.read_csv(\"train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_images_by_dir(base_dir=\"train\"):\n",
    "    \"\"\"\n",
    "    Move images into their label directory so that they can be recognized by\n",
    "    ImageDataGenerator.flow_from_directory\n",
    "    \"\"\"\n",
    "    for _, row in train_labels_csv.iterrows():\n",
    "        image_name = \"{}.jpg\".format(row['name'])\n",
    "        src_path = os.path.join(base_dir, image_name)\n",
    "        if row['invasive'] == 1:\n",
    "            dst_path = os.path.join(base_dir, 'invasive', image_name)\n",
    "        else:\n",
    "            dst_path = \"train/not_invasive/{}\".format(image_name)\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.move(src_path, dst_path)\n",
    "# label_images_by_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_valid_set(train_root='train', valid_root=\"valid\", valid_rate=0.1):\n",
    "    labels = ['invasive', 'not_invasive']\n",
    "    for label in labels:\n",
    "        train_label_dir = os.path.join(train_root, label)\n",
    "        valid_label_dir = os.path.join(valid_root, label)\n",
    "        files = os.listdir(train_label_dir)\n",
    "        for file in random.sample(files, k=int(len(files) * valid_rate)):\n",
    "            shutil.move(os.path.join(train_label_dir, file), valid_label_dir)\n",
    "#  create_valid_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_sample_set(rate=0.01):\n",
    "    labels = ['invasive', 'not_invasive', 'unknown']\n",
    "    for dataset in ['train', 'valid', 'test']:\n",
    "        if dataset == \"valid\":\n",
    "            # use a higher smple rate for the validation dataset\n",
    "            # because they have fewer items\n",
    "            sample_rate = rate*5\n",
    "        else:\n",
    "            sample_rate = rate\n",
    "        for label in labels:\n",
    "            src_dir = os.path.join(dataset, label)\n",
    "            dst_dir = os.path.join('sample', dataset, label)\n",
    "            try:\n",
    "                files = os.listdir(src_dir)\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            for file in random.sample(files, k=int(len(files) * sample_rate)):\n",
    "                shutil.copy(os.path.join(src_dir, file), dst_dir)\n",
    "\n",
    "# create_sample_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_preprocess(x):\n",
    "    \"\"\"\n",
    "        Subtracts the mean RGB value, and transposes RGB to BGR.\n",
    "        The mean RGB was computed on the image set used to train the VGG model.\n",
    "\n",
    "        Args: \n",
    "            x: Image array (height x width x channels)\n",
    "        Returns:\n",
    "            Image array (height x width x transposed_channels)\n",
    "    \"\"\"\n",
    "    vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((3,1,1))\n",
    "    x = x - vgg_mean\n",
    "    return x[:, ::-1] # reverse axis rgb->bgr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addConvBlock(model, layers, filters):\n",
    "    \"\"\"\n",
    "        Adds a specified number of ZeroPadding and Covolution layers\n",
    "        to the model, and a MaxPooling layer at the very end.\n",
    "\n",
    "        Args:\n",
    "            layers (int):   The number of zero padded convolution layers\n",
    "                            to be added to the model.\n",
    "            filters (int):  The number of convolution filters to be \n",
    "                            created for each layer.\n",
    "    \"\"\"\n",
    "    for i in range(layers):\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addFCBlock(model):\n",
    "    \"\"\"\n",
    "        Adds a fully connected layer of 4096 neurons to the model with a\n",
    "        Dropout of 0.5\n",
    "\n",
    "        Args:   None\n",
    "        Returns:   None\n",
    "    \"\"\"\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build Vgg model\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(vgg_preprocess, input_shape=(3,224,224), output_shape=(3,224,224)))\n",
    "\n",
    "    addConvBlock(model, 2, 64)\n",
    "    addConvBlock(model, 2, 128)\n",
    "    addConvBlock(model, 3, 256)\n",
    "    addConvBlock(model, 3, 512)\n",
    "    addConvBlock(model, 3, 512)\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "\n",
    "    addFCBlock(model)\n",
    "    addFCBlock(model)\n",
    "\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    fname = 'vgg16.h5'\n",
    "    model.load_weights(get_file(fname, 'http://files.fast.ai/models/'+fname, cache_subdir='models'))\n",
    "    return model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(path, gen=image.ImageDataGenerator(), shuffle=True, batch_size=8, class_mode='categorical'):\n",
    "        \"\"\"\n",
    "            Takes the path to a directory, and generates batches of augmented/normalized data. Yields batches indefinitely, in an infinite loop.\n",
    "\n",
    "            See Keras documentation: https://keras.io/preprocessing/image/\n",
    "        \"\"\"\n",
    "        # 224x224 is the image size used by ImageNet\n",
    "        return gen.flow_from_directory(path, target_size=(224,224),\n",
    "                class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_path = DATA_HOME_DIR\n",
    "# _path = DATA_HOME_DIR + '/sample' # Only for sample tests!\n",
    "test_path = os.path.join(DATA_HOME_DIR, 'test')\n",
    "results_path = os.path.join(DATA_HOME_DIR, 'results')\n",
    "train_path = os.path.join(_path, 'train')\n",
    "valid_path = os.path.join(_path, 'valid')\n",
    "test_path = os.path.join(_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2067 images belonging to 2 classes.\n",
      "Found 228 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "! cd $NB_ROOT\n",
    "BATCH_SIZE=64\n",
    "\n",
    "train_batches = get_batches(train_path, batch_size=BATCH_SIZE)\n",
    "valid_batches = get_batches(valid_path, batch_size=BATCH_SIZE*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def finetune(model, output_size, lr=0.001):\n",
    "    # Replace the last layer with a new Dense\n",
    "    model.pop()\n",
    "    for layer in model.layers:\n",
    "        layer.trainable=False\n",
    "    model.add(Dense(output_size, activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=lr),\n",
    "        loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finetune(model, train_batches.nb_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(model):\n",
    "    no_of_epochs = 3\n",
    "    latest_weights_filename = None\n",
    "    for epoch in range(no_of_epochs):\n",
    "        print(\"Running epoch: %d\" % epoch)\n",
    "        model.fit_generator(\n",
    "            train_batches, samples_per_epoch=train_batches.nb_sample,\n",
    "            nb_epoch=1,\n",
    "            validation_data=valid_batches, nb_val_samples=valid_batches.nb_sample\n",
    "        )\n",
    "        latest_weights_filename = 'ft%d.h5' % epoch\n",
    "        model.save_weights(results_path+latest_weights_filename)\n",
    "        print(\"Completed %s fit operations\" % no_of_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 0\n",
      "Epoch 1/1\n",
      "2067/2067 [==============================] - 584s - loss: 1.5531 - acc: 0.8229 - val_loss: 0.6040 - val_acc: 0.9254\n",
      "Completed 3 fit operations\n",
      "Running epoch: 1\n",
      "Epoch 1/1\n",
      "2067/2067 [==============================] - 583s - loss: 0.9182 - acc: 0.8771 - val_loss: 0.4460 - val_acc: 0.9211\n",
      "Completed 3 fit operations\n",
      "Running epoch: 2\n",
      "Epoch 1/1\n",
      "2067/2067 [==============================] - 584s - loss: 1.0436 - acc: 0.8689 - val_loss: 0.8964 - val_acc: 0.8684\n",
      "Completed 3 fit operations\n"
     ]
    }
   ],
   "source": [
    "fit_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1531 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = get_batches(\n",
    "    test_path, batch_size=BATCH_SIZE * 2, shuffle=False, class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, test_batches):\n",
    "    return model.predict_generator(test_batches, test_batches.nb_sample)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = predict(model, test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_files = test_batches.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sbm = pd.DataFrame(preds, columns=[\"invasive\",\"not invasive\"])\n",
    "sbm['name'] = [int(f.replace('unknown/', '').replace('.jpg', '')) for f in test_batches.filenames]\n",
    "sbm = sbm.set_index(['name'])\n",
    "sbm = sbm.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sbm.to_csv('submission.csv', columns=['invasive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "!kg submit -c invasive-species-monitoring submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
